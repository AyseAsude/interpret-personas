{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Test: Hook-Based Activation Extraction + SAE\n",
    "\n",
    "Tests:\n",
    "1. Model/SAE loading via `load_sae_model`\n",
    "2. Layer index parsing from SAE hook name\n",
    "3. Hook captures correct activations (verified against `output_hidden_states`)\n",
    "4. SAE reconstruction quality (FVU) and L0 sparsity\n",
    "5. `FeatureExtractor` end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Model & SAE via `load_sae_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret_personas.extraction.sae_loader import load_sae_model\n",
    "\n",
    "model, sae, tokenizer = load_sae_model(\n",
    "    model_name=\"google/gemma-3-27b-it\",\n",
    "    sae_release=\"gemma-scope-2-27b-it-res\",\n",
    "    sae_id=\"layer_40_width_65k_l0_medium\",\n",
    ")\n",
    "\n",
    "print(f\"Model type: {type(model).__name__}\")\n",
    "print(f\"SAE hook: {sae.cfg.metadata.hook_name}\")\n",
    "print(f\"SAE dimensions: d_in={sae.cfg.d_in}, d_sae={sae.cfg.d_sae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Layer Index Parsing\n",
    "\n",
    "Verify `_parse_layer_index` extracts the correct layer from the SAE's hook name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret_personas.extraction.feature_extractor import FeatureExtractor, _gather_residual_activations\n",
    "\n",
    "LAYER = FeatureExtractor._parse_layer_index(sae.cfg.metadata.hook_name)\n",
    "print(f\"Hook name: {sae.cfg.metadata.hook_name}\")\n",
    "print(f\"Parsed layer: {LAYER}\")\n",
    "assert LAYER == 40, f\"Expected layer 40, got {LAYER}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Hook-Based Activation Capture\n",
    "\n",
    "Test `_gather_residual_activations` on a simple input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "inputs = tokenizer.encode(test_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "target_act = _gather_residual_activations(model, LAYER, inputs)\n",
    "print(f\"Input shape: {inputs.shape}\")\n",
    "print(f\"Activation shape: {target_act.shape}\")\n",
    "print(f\"Activation dtype: {target_act.dtype}\")\n",
    "print(f\"Activation device: {target_act.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Verify Hook vs `output_hidden_states`\n",
    "\n",
    "Sanity check: hook output should match `output_hidden_states` at the same layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs, output_hidden_states=True)\n",
    "\n",
    "# hidden_states[0] = embeddings, hidden_states[L+1] = output of layer L\n",
    "ohs_act = outputs.hidden_states[LAYER + 1]\n",
    "\n",
    "max_diff = (target_act - ohs_act).abs().max().item()\n",
    "print(f\"Max absolute difference (hook vs output_hidden_states): {max_diff}\")\n",
    "assert max_diff < 1e-5, f\"Mismatch! max_diff={max_diff}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. SAE Encode / Decode + FVU\n",
    "\n",
    "Fraction of Variance Unexplained measures reconstruction quality.\n",
    "Lower is better (< 10% is typical for a well-trained SAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_acts = sae.encode(target_act.to(sae.dtype).to(sae.device))\n",
    "recon = sae.decode(sae_acts)\n",
    "\n",
    "# Skip BOS token (position 0) for FVU â€” SAE may not have been trained on it\n",
    "reconstruction_mse = torch.mean((recon[:, 1:] - target_act[:, 1:].to(sae.dtype)) ** 2)\n",
    "target_variance = target_act[:, 1:].to(sae.dtype).var()\n",
    "\n",
    "fvu = reconstruction_mse / target_variance\n",
    "print(f\"Fraction of variance unexplained: {fvu:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. L0 Sparsity\n",
    "\n",
    "Number of active features per token. Should be sparse (typical: 50-200 active out of 65k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "l0_per_token = (sae_acts > 0).sum(-1)[0]\n",
    "print(f\"L0 per token: {l0_per_token.tolist()}\")\n",
    "print(f\"Average L0 (excluding BOS): {l0_per_token[1:].float().mean():.2f}\")\n",
    "print(f\"SAE feature shape: {sae_acts.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. Test `FeatureExtractor` End-to-End\n",
    "\n",
    "Verify the full class produces correct output shapes and sensible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris, a city known for the Eiffel Tower and its rich cultural heritage.\"},\n",
    "]\n",
    "\n",
    "extractor = FeatureExtractor(model=model, sae=sae, tokenizer=tokenizer)\n",
    "print(f\"Target layer: {extractor._target_layer}\")\n",
    "assert extractor._target_layer == LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = extractor.extract_from_conversation(conversation, token_selection=\"response_only\")\n",
    "\n",
    "print(f\"Mean feature shape: {result['mean'].shape}\")\n",
    "print(f\"Max feature shape: {result['max'].shape}\")\n",
    "print(f\"Mean vector L2 norm: {np.linalg.norm(result['mean']):.4f}\")\n",
    "print(f\"Max vector L2 norm: {np.linalg.norm(result['max']):.4f}\")\n",
    "print(f\"Nonzero mean features: {(result['mean'] > 0).sum()}\")\n",
    "print(f\"Nonzero max features: {(result['max'] > 0).sum()}\")\n",
    "\n",
    "assert result[\"mean\"].shape == (sae.cfg.d_sae,)\n",
    "assert result[\"max\"].shape == (sae.cfg.d_sae,)\n",
    "assert result[\"mean\"].max() > 0, \"Mean features should have positive activations\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all = extractor.extract_from_conversation(conversation, token_selection=\"all\")\n",
    "\n",
    "print(f\"response_only mean L2: {np.linalg.norm(result['mean']):.4f}\")\n",
    "print(f\"all tokens mean L2:    {np.linalg.norm(result_all['mean']):.4f}\")\n",
    "print(f\"\\nVectors differ: {not np.allclose(result['mean'], result_all['mean'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results = extractor.extract_batch(\n",
    "    [\n",
    "        conversation,\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Explain photosynthesis briefly.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Photosynthesis converts sunlight, water, and CO2 into glucose and oxygen.\"},\n",
    "        ],\n",
    "    ],\n",
    "    token_selection=\"response_only\",\n",
    ")\n",
    "\n",
    "print(f\"Batch size: {len(batch_results)}\")\n",
    "for i, r in enumerate(batch_results):\n",
    "    print(f\"  Conv {i}: mean shape={r['mean'].shape}, max shape={r['max'].shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
